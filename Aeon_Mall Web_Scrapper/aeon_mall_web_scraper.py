# -*- coding: utf-8 -*-
"""Aeon Mall  web_scraper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wZjQfEh11-PY8hh2P1U0vHaSDJQ6iy5C
"""

pip install requests

pip install beautifulsoup4

# Import Library
import requests
from bs4 import BeautifulSoup

page = 1
datas = []

while (page <= 19) :
  url = 'https://aeonmall-bsdcity.com/shopping.php?page=' + str(page)
  web = requests.get(url)
  soup = BeautifulSoup(web.content, 'html.parser')
  # Find all div tags on the webpage containing the information we want to scrape
  divs = soup.find_all('div', class_='desc-shopping')

  datas.append(divs)

  page = page + 1


print(datas)

i = 0
store_name = []
store_type = []
store_location = []

while (i <= (len(datas) - 1)):
  for data in datas[i] :
    # Extracting all 'h3' tags
    store_name.append(data.find('h3').text)
    # Extracting all 'span' tags
    store_type.append(data.find('span').text)
    # Extracting all 'div(class=tmaps)' tags
    store_location.append(data.find('div', class_="tmaps").text)
  i = i + 1

# View store_name values
store_name[:5]

# View store_type
store_type[:5]

# View store_location values
store_location[:5]

i = 0
desc = []

while (i <= (len(datas) - 1)) :
  for lnk in datas[i] :
    # Extracting all 'a' and 'href' tags
    link = lnk.find('a')['href']
    url = 'https://aeonmall-bsdcity.com/' + link
    web = requests.get(url)
    soup = BeautifulSoup(web.content, 'html.parser')
    # Extracting all article(class='bss') tags
    articles = soup.find('article', class_="bss").text

    desc.append(articles)

  i = i + 1

# View desc values
desc[:5]

print(desc[0].strip('\r\n + ()'))

# Strip '\r' and '\n' from desc values
desc = [articles.strip('\r\n + ()') for articles in desc]

# View desc stripped values
desc[:5]

import pandas as pd

# Create Dataframe
stores_info = pd.DataFrame()
stores_info  # The dataframe is still empty, we need to fill it with the info we gathered

# Populating dataframe
stores_info['Store Names'] = store_name
stores_info['Store Type'] = store_type
stores_info['Location'] = store_location
stores_info['Description'] = desc

# View dataframe values
stores_info.head()

# Write data to CSV file
stores_info.to_csv("stores_info.csv", index = False, header = True)