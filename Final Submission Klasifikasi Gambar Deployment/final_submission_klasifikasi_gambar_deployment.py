# -*- coding: utf-8 -*-
"""Final Submission Klasifikasi Gambar Deployment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ce2CDlqHlf0aCPxXp5OdNpXRuj7ERcJx
"""

# Menginstal package kaggle
!pip install -q kaggle

from google.colab import files

# Mengupload file json dari profile kaggle
files.upload()

# Membuat direktory dan mengubah izin file
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

# Download dataset
!kaggle datasets download -d piyushkumar18/animal-image-classification-dataset

import zipfile
local_zip = '/content/animal-image-classification-dataset.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

pip install split_folders

"""Dataset di bagi pada bagian ini"""

import os, splitfolders

# Membagi dataset
base_dir = '/content/Animal Image Dataset'
splitfolders.ratio(base_dir, output ='/content/Animal Image Dataset', ratio=(0.8, 0.2)) # Note to reviewer

# Membuat direktori train dan validasi
train_dir = os.path.join('/content/Animal Image Dataset', 'train')
validation_dir = os.path.join('/content/Animal Image Dataset', 'val')

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Membuat objek ImageDataGenerator untuk data training
train_datagen = ImageDataGenerator(rescale=1./255,
    horizontal_flip=True,
    rotation_range=30,
    zoom_range=0.3,
    shear_range=0.2,
    brightness_range=[0.4,1.5],
    fill_mode = 'nearest',) # validation split

# Membuat objek ImageDataGenerator untuk data testing
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_dir, # Direktori data latih
        target_size=(150, 200),
        batch_size=32,
        shuffle=True,
        color_mode='rgb',
        class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(
        validation_dir, # Direktori data validasi
        target_size=(150, 200),
        batch_size=32,
        shuffle=True,
        color_mode='rgb',
        class_mode='categorical')

import tensorflow as tf
from tensorflow.keras.layers import Input
from tensorflow.keras.applications import ResNet152V2

# Membuat arsitektur CNN dengan Keras
model = tf.keras.models.Sequential([
    ResNet152V2(weights="imagenet", include_top=False, input_tensor=Input(shape=(150, 200, 3))),
    tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),
    tf.keras.layers.MaxPool2D(2, 2),    
    tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='same'),
    tf.keras.layers.MaxPool2D(2, 2),    
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(12, activation='softmax') 
])
model.layers[0].trainable = False

model.summary()

# Compile model dengan Adam (loss function 'categorical_crossentropy')
model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(learning_rate=0.0001),
              metrics=['accuracy'])

from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping

filepath_acc='/content/best_acc_weights.h5'
filepath_loss='/content/best_loss_weights.h5'

# Model checkpoint untuk menyimpan best acc/loss model
checkpoint_loss = ModelCheckpoint(filepath_loss, verbose=1, monitor='val_loss', save_best_only=True, mode='min')
checkpoint_acc = ModelCheckpoint(filepath_acc, verbose=1, monitor='val_accuracy', save_best_only=True, mode='max')

early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)

reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=0.1, patience=3, min_delta=1e-2, verbose=1)

# Membuat custom callbacks
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.92 and logs.get('val_accuracy') > 0.92):
      print('\nCongratulation accuracy has reach beyond 92%')
      self.model.stop_training = True

callbacks_list = [checkpoint_loss, checkpoint_acc,
                  early_stopping, reduce_lr, myCallback()]

hist = model.fit(
            train_generator, epochs=100, steps_per_epoch=128,
            validation_data=validation_generator, validation_steps=20,
            verbose=1, callbacks=callbacks_list)

import matplotlib.pyplot as plt

# Plot Accuracy
plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('Accuracy Model')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Plot Loss
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Convert the model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
  f.write(tflite_model)